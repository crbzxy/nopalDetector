#!/usr/bin/env python3
"""
"""
ğŸ§ª Script de Prueba Integral - Nopal Detector
Verifica todas las funcionalidades principales del sistema
"""
"""

import os
import sys
import yaml
import subprocess
from pathlib import Path

def print_header(title):
    """Imprimi        print("ğŸ’¡ PRÃ“XIMOS PASOS:")
        print("   1. Probar actualizaciÃ³n: python update_labels.py")
        print("   2. Entrenar modelo: python main.py --mode train --multi-class")
        print("   3. Probar detecciÃ³n: python main.py --mode predict --input imagen.jpg --multi-class")cabezado de secciÃ³n"""
    print(f"\n{'='*60}")
    print(f"ğŸ§ª {title}")
    print(f"{'='*60}")

def run_command(command, description):
    """Ejecutar comando y mostrar resultado"""
    print(f"\nğŸ”„ {description}")
    print(f"ğŸ“ Comando: {command}")
    
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… Ã‰xito!")
            if result.stdout.strip():
                print(f"ğŸ“„ Salida:\n{result.stdout}")
        else:
            print("âŒ Error!")
            print(f"ğŸš¨ Error: {result.stderr}")
            
        return result.returncode == 0
        
    except Exception as e:
        print(f"âŒ ExcepciÃ³n: {e}")
        return False

def check_file_exists(file_path, description):
    """Verificar que un archivo existe"""
    if os.path.exists(file_path):
        print(f"âœ… {description}: {file_path}")
        return True
    else:
        print(f"âŒ {description} no encontrado: {file_path}")
        return False

def test_label_updater():
    """Probar el sistema de actualizaciÃ³n de etiquetas"""
    print_header("PRUEBA DE ACTUALIZACIÃ“N DE ETIQUETAS")
    
    # Verificar que existe el archivo update_labels.py
    if not check_file_exists("update_labels.py", "Script de actualizaciÃ³n"):
        return False
    
    # Probar la clase LabelUpdater
    print("\nğŸ” Probando LabelUpdater...")
    
    test_code = """
import sys
sys.path.append('.')
from update_labels import LabelUpdater
import yaml

# Cargar configuraciÃ³n
with open('config/model_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Crear updater
updater = LabelUpdater(config)
print("âœ… LabelUpdater creado exitosamente")

# Verificar configuraciÃ³n actual
print(f"ğŸ“Š Dataset actual: nopal-detector-{updater.current_version}")
print(f"ğŸ”— Workspace: {updater.workspace_id}")
print(f"ğŸ“‹ Proyecto: {updater.project_name}")
"""
    
    try:
        exec(test_code)
        return True
    except Exception as e:
        print(f"âŒ Error probando LabelUpdater: {e}")
        return False

def test_multi_class_detector():
    """Probar el detector multi-clase"""
    print_header("PRUEBA DE DETECTOR MULTI-CLASE")
    
    # Verificar que existe el archivo
    if not check_file_exists("src/models/multi_class_detector.py", "Detector multi-clase"):
        return False
    
    # Probar la clase MultiClassDetector
    print("\nğŸ” Probando MultiClassDetector...")
    
    test_code = """
import sys
sys.path.append('src')
from models.multi_class_detector import MultiClassDetector
import yaml

# Cargar configuraciÃ³n
with open('config/model_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Crear detector
detector = MultiClassDetector(config)
print("âœ… MultiClassDetector creado exitosamente")
print(f"ğŸ·ï¸ Clases cargadas: {detector.class_names}")
print(f"ğŸ¨ Colores generados: {len(detector.class_colors)} colores")
"""
    
    try:
        exec(test_code)
        return True
    except Exception as e:
        print(f"âŒ Error probando MultiClassDetector: {e}")
        return False

def test_config_files():
    """Verificar archivos de configuraciÃ³n"""
    print_header("VERIFICACIÃ“N DE CONFIGURACIÃ“N")
    
    config_files = [
        ("config/model_config.yaml", "ConfiguraciÃ³n del modelo"),
        ("config/training_config.yaml", "ConfiguraciÃ³n de entrenamiento"),
        ("nopal-detector-2/data.yaml", "Dataset configuration")
    ]
    
    all_good = True
    for file_path, description in config_files:
        if not check_file_exists(file_path, description):
            all_good = False
        else:
            # Verificar que se puede cargar
            try:
                with open(file_path, 'r') as f:
                    data = yaml.safe_load(f)
                print(f"   ğŸ“‹ Contenido vÃ¡lido YAML")
            except Exception as e:
                print(f"   âŒ Error leyendo YAML: {e}")
                all_good = False
    
    return all_good

def test_dataset_structure():
    """Verificar estructura del dataset"""
    print_header("VERIFICACIÃ“N DE DATASET")
    
    dataset_dirs = [
        "nopal-detector-2/train/images",
        "nopal-detector-2/train/labels", 
        "nopal-detector-2/valid/images",
        "nopal-detector-2/valid/labels",
        "nopal-detector-2/test/images",
        "nopal-detector-2/test/labels"
    ]
    
    all_good = True
    for dir_path in dataset_dirs:
        if os.path.exists(dir_path):
            count = len([f for f in os.listdir(dir_path) if not f.startswith('.')])
            print(f"âœ… {dir_path}: {count} archivos")
        else:
            print(f"âŒ {dir_path}: no encontrado")
            all_good = False
    
    return all_good

def test_model_weights():
    """Verificar pesos del modelo"""
    print_header("VERIFICACIÃ“N DE MODELOS")
    
    model_paths = [
        "yolo11s.pt",
        "runs/detect/train2/weights/best.pt",
        "runs/detect/train2/weights/last.pt"
    ]
    
    weights_found = 0
    for model_path in model_paths:
        if check_file_exists(model_path, f"Modelo {model_path}"):
            weights_found += 1
            
            # Verificar tamaÃ±o del archivo
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            print(f"   ğŸ“ TamaÃ±o: {size_mb:.1f} MB")
    
    return weights_found > 0

def test_integration():
    """Prueba de integraciÃ³n bÃ¡sica"""
    print_header("PRUEBA DE INTEGRACIÃ“N")
    
    # Verificar que se puede importar todo
    print("\nğŸ” Probando imports...")
    
    try:
        # Test import de update_labels
        from update_labels import LabelUpdater
        print("âœ… update_labels importado")
        
        # Test import bÃ¡sico de configuraciÃ³n
        import yaml
        with open('config/model_config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        print("âœ… ConfiguraciÃ³n cargada")
        
        # Test de creaciÃ³n de objetos principales
        updater = LabelUpdater(config)
        print("âœ… LabelUpdater instanciado")
        
        print("âœ… Todos los imports y instanciaciones exitosas")
        return True
        
    except Exception as e:
        print(f"âŒ Error en integraciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """FunciÃ³n principal de pruebas"""
    print("ğŸŒµ =======================================")
    print("ğŸŒµ   NOPAL DETECTOR - TESTS")
    print("ğŸŒµ   Prueba Integral del Sistema")
    print("ğŸŒµ =======================================")
    
    # Verificar que estamos en el directorio correcto
    if not os.path.exists("main.py"):
        print("âŒ Error: Ejecutar desde el directorio raÃ­z del proyecto")
        return False
    
    # Lista de pruebas
    tests = [
        ("ConfiguraciÃ³n", test_config_files),
        ("Dataset", test_dataset_structure),
        ("Modelos", test_model_weights),
        ("ActualizaciÃ³n de Etiquetas", test_label_updater),
        ("Detector Multi-Clase", test_multi_class_detector),
        ("IntegraciÃ³n", test_integration)
    ]
    
    # Ejecutar pruebas
    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ Error en prueba {test_name}: {e}")
            results[test_name] = False
    
    # Mostrar resumen
    print_header("RESUMEN DE PRUEBAS")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} {test_name}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ RESULTADO FINAL: {passed}/{total} pruebas exitosas")
    
    if passed == total:
        print("ğŸ‰ Â¡Todas las pruebas pasaron! Sistema listo para usar.")
        print("\nğŸ’¡ PRÃ“XIMOS PASOS:")
        print("   1. Probar actualizaciÃ³n: python update_labels.py")
        print("   2. Entrenar modelo: python main_v3.py --mode train --multi-class")
        print("   3. Probar detecciÃ³n: python main_v3.py --mode predict --input imagen.jpg --multi-class")
    else:
        print("âš ï¸ Algunas pruebas fallaron. Revisar errores arriba.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)