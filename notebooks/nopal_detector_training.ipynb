{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9c3428",
   "metadata": {},
   "source": [
    "# Nopal Detector con YOLOv11 üåµ + Personas\n",
    "\n",
    "Notebook optimizado para entrenamiento y predicciones en im√°genes y video.\n",
    "\n",
    "## üéØ Objetivo\n",
    "- Entrenar un modelo YOLOv11 para detectar nopales\n",
    "- Detectar personas usando modelo preentrenado\n",
    "- Procesar im√°genes y videos con detecciones duales\n",
    "\n",
    "## üèóÔ∏è Arquitectura\n",
    "Este notebook utiliza una arquitectura modular con clases especializadas:\n",
    "- `DatasetManager`: Gesti√≥n del dataset de Roboflow\n",
    "- `NopalPersonDetector`: Entrenamiento y predicciones\n",
    "- `ResultVisualizer`: Visualizaci√≥n de resultados\n",
    "\n",
    "## üìä Flujo de Trabajo\n",
    "1. **Instalaci√≥n** de dependencias\n",
    "2. **Descarga** del dataset desde Roboflow\n",
    "3. **Preparaci√≥n** y validaci√≥n del dataset\n",
    "4. **Entrenamiento** del modelo YOLOv11\n",
    "5. **Predicciones** en im√°genes de test\n",
    "6. **Procesamiento** de video\n",
    "7. **Descarga** de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6056565",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Librer√≠as Necesarias üõ†Ô∏è\n",
    "\n",
    "Instalamos las librer√≠as requeridas para el proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8800743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de librer√≠as necesarias\n",
    "!pip install roboflow ultralytics supervision opencv-python PyYAML matplotlib -q\n",
    "\n",
    "print(\"‚úÖ Librer√≠as instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67aa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Agregar el directorio src al path para importar nuestras clases\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"üìö Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b8357",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n del Proyecto ‚öôÔ∏è\n",
    "\n",
    "Cargar la configuraci√≥n y inicializar las clases necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881992a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar configuraci√≥n del proyecto\n",
    "import os\n",
    "try:\n",
    "    from utils.config import load_config_with_env, setup_environment\n",
    "    print(\"‚úÖ Utilidades de configuraci√≥n importadas\")\n",
    "    \n",
    "    # Configurar entorno\n",
    "    setup_environment()\n",
    "    \n",
    "    # Cargar configuraci√≥n\n",
    "    CONFIG_PATH = \"../config/model_config.yaml\"\n",
    "    if os.path.exists(CONFIG_PATH):\n",
    "        config = load_config_with_env(CONFIG_PATH)\n",
    "        print(\"‚úÖ Configuraci√≥n cargada con variables de entorno\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No se encontr√≥ {CONFIG_PATH}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è No se pudieron importar utilidades, usando configuraci√≥n manual\")\n",
    "    \n",
    "    # Cargar variables de entorno manualmente\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv(\"../.env\")\n",
    "        print(\"‚úÖ Variables de entorno cargadas desde .env\")\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è python-dotenv no disponible, usando variables del sistema\")\n",
    "    \n",
    "    # Verificar API key\n",
    "    roboflow_api_key = os.getenv('ROBOFLOW_API_KEY')\n",
    "    if not roboflow_api_key:\n",
    "        print(\"‚ùå ROBOFLOW_API_KEY no encontrada!\")\n",
    "        print(\"   1. Copia .env.example como .env\")\n",
    "        print(\"   2. Completa ROBOFLOW_API_KEY con tu API key\")\n",
    "        print(\"   3. O exporta: export ROBOFLOW_API_KEY=tu_api_key\")\n",
    "        roboflow_api_key = input(\"Ingresa tu API key de Roboflow: \")\n",
    "    \n",
    "    # Configuraci√≥n para Colab y local\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\"üîç Detectado Google Colab\")\n",
    "        # En Colab, configurar variables de entorno\n",
    "        os.environ['ROBOFLOW_API_KEY'] = roboflow_api_key\n",
    "        \n",
    "        config = {\n",
    "            'roboflow': {\n",
    "                'api_key': roboflow_api_key,\n",
    "                'workspace': os.getenv('ROBOFLOW_WORKSPACE', 'nopaldetector'),\n",
    "                'project': os.getenv('ROBOFLOW_PROJECT', 'nopal-detector-0lzvl'),\n",
    "                'version': int(os.getenv('ROBOFLOW_VERSION', '2')),\n",
    "                'format': 'yolov11'\n",
    "            },\n",
    "            'model': {\n",
    "                'base_model': 'yolo11s.pt',\n",
    "                'person_model': 'yolo11s.pt',\n",
    "                'training': {\n",
    "                    'epochs': 50,\n",
    "                    'batch_size': 16,\n",
    "                    'image_size': 640,\n",
    "                    'patience': 10\n",
    "                },\n",
    "                'prediction': {\n",
    "                    'confidence_threshold': float(os.getenv('MODEL_CONFIDENCE_THRESHOLD', '0.3')),\n",
    "                    'iou_threshold': float(os.getenv('MODEL_IOU_THRESHOLD', '0.5'))\n",
    "                }\n",
    "            },\n",
    "            'data': {\n",
    "                'validation_split': 0.2,\n",
    "                'random_seed': 42\n",
    "            },\n",
    "            'output': {\n",
    "                'predictions_dir': '/content/predictions',\n",
    "                'videos_dir': '/content/videos',\n",
    "                'weights_dir': '/content/weights'\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        # Configuraci√≥n local\n",
    "        config = {\n",
    "            'roboflow': {\n",
    "                'api_key': roboflow_api_key,\n",
    "                'workspace': os.getenv('ROBOFLOW_WORKSPACE', 'nopaldetector'),\n",
    "                'project': os.getenv('ROBOFLOW_PROJECT', 'nopal-detector-0lzvl'),\n",
    "                'version': int(os.getenv('ROBOFLOW_VERSION', '2')),\n",
    "                'format': 'yolov11'\n",
    "            },\n",
    "            'model': {\n",
    "                'base_model': 'yolo11s.pt',\n",
    "                'person_model': 'yolo11s.pt',\n",
    "                'training': {\n",
    "                    'epochs': 50,\n",
    "                    'batch_size': 16,\n",
    "                    'image_size': 640,\n",
    "                    'patience': 10\n",
    "                },\n",
    "                'prediction': {\n",
    "                    'confidence_threshold': float(os.getenv('MODEL_CONFIDENCE_THRESHOLD', '0.3')),\n",
    "                    'iou_threshold': float(os.getenv('MODEL_IOU_THRESHOLD', '0.5'))\n",
    "                }\n",
    "            },\n",
    "            'data': {\n",
    "                'validation_split': 0.2,\n",
    "                'random_seed': 42\n",
    "            },\n",
    "            'output': {\n",
    "                'predictions_dir': '../outputs/predictions',\n",
    "                'videos_dir': '../outputs/videos',\n",
    "                'weights_dir': '../models/weights'\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"üéØ Configuraci√≥n lista\")\n",
    "print(f\"üìä √âpocas de entrenamiento: {config['model']['training']['epochs']}\")\n",
    "print(f\"üé® Tama√±o de imagen: {config['model']['training']['image_size']}\")\n",
    "print(f\"üéØ Umbral de confianza: {config['model']['prediction']['confidence_threshold']}\")\n",
    "print(f\"üîë API key configurada: {'‚úÖ' if config['roboflow']['api_key'] else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97020fbf",
   "metadata": {},
   "source": [
    "## 3. Descarga de Dataset desde Roboflow üóÇÔ∏è\n",
    "\n",
    "Conectamos con la API de Roboflow y descargamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar y usar DatasetManager\n",
    "try:\n",
    "    from data.dataset_manager import DatasetManager\n",
    "    print(\"‚úÖ DatasetManager importado correctamente\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è No se pudo importar DatasetManager, usando implementaci√≥n directa\")\n",
    "    \n",
    "    # Implementaci√≥n directa para Colab\n",
    "    from roboflow import Roboflow\n",
    "    import shutil\n",
    "    import random\n",
    "    \n",
    "    # Descargar dataset\n",
    "    rf = Roboflow(api_key=config['roboflow']['api_key'])\n",
    "    project = rf.workspace(config['roboflow']['workspace']).project(config['roboflow']['project'])\n",
    "    version = project.version(config['roboflow']['version'])\n",
    "    dataset = version.download(config['roboflow']['format'])\n",
    "    \n",
    "    dataset_location = dataset.location\n",
    "    print(f\"‚úÖ Dataset descargado en: {dataset_location}\")\n",
    "else:\n",
    "    # Usar clase DatasetManager\n",
    "    dataset_manager = DatasetManager(config)\n",
    "    dataset_location = dataset_manager.download_dataset()\n",
    "    \n",
    "print(f\"üìÇ Ubicaci√≥n del dataset: {dataset_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f78f4f",
   "metadata": {},
   "source": [
    "## 4. Preparaci√≥n y Validaci√≥n del Dataset üìÇ\n",
    "\n",
    "Organizamos las carpetas del dataset y creamos el split de validaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset\n",
    "if 'dataset_manager' in locals():\n",
    "    # Usar DatasetManager\n",
    "    dataset_paths = dataset_manager.prepare_dataset()\n",
    "    data_yaml_path = dataset_manager.get_data_yaml_path()\n",
    "else:\n",
    "    # Implementaci√≥n directa\n",
    "    base_dir = dataset_location\n",
    "    \n",
    "    # Definir rutas\n",
    "    train_img_dir = os.path.join(base_dir, \"train/images\")\n",
    "    train_lbl_dir = os.path.join(base_dir, \"train/labels\")\n",
    "    valid_img_dir = os.path.join(base_dir, \"valid/images\")\n",
    "    valid_lbl_dir = os.path.join(base_dir, \"valid/labels\")\n",
    "    test_img_dir = os.path.join(base_dir, \"test/images\")\n",
    "    test_lbl_dir = os.path.join(base_dir, \"test/labels\")\n",
    "    \n",
    "    # Crear todas las carpetas si no existen\n",
    "    for d in [train_img_dir, train_lbl_dir, valid_img_dir, valid_lbl_dir, test_img_dir, test_lbl_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    # Si no hay validaci√≥n, crear un 20% de split desde train\n",
    "    if not os.listdir(valid_img_dir):\n",
    "        all_imgs = [f for f in os.listdir(train_img_dir) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))]\n",
    "        if all_imgs:\n",
    "            random.seed(config['data']['random_seed'])\n",
    "            split_size = max(1, int(len(all_imgs) * config['data']['validation_split']))\n",
    "            sampled = random.sample(all_imgs, split_size)\n",
    "            \n",
    "            for img in sampled:\n",
    "                lbl = os.path.splitext(img)[0] + \".txt\"\n",
    "                shutil.move(os.path.join(train_img_dir, img), os.path.join(valid_img_dir, img))\n",
    "                if os.path.exists(os.path.join(train_lbl_dir, lbl)):\n",
    "                    shutil.move(os.path.join(train_lbl_dir, lbl), os.path.join(valid_lbl_dir, lbl))\n",
    "            \n",
    "            print(f\"‚ö†Ô∏è No hab√≠a validaci√≥n, se movieron {len(sampled)} im√°genes a valid/\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No hay im√°genes en train para dividir en valid.\")\n",
    "    \n",
    "    # Actualizar data.yaml\n",
    "    data_yaml_path = os.path.join(base_dir, \"data.yaml\")\n",
    "    with open(data_yaml_path, \"r\") as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    \n",
    "    data_yaml[\"train\"] = train_img_dir\n",
    "    data_yaml[\"val\"] = valid_img_dir\n",
    "    \n",
    "    # Solo incluir test si hay im√°genes\n",
    "    if any(f.lower().endswith((\".jpg\",\".jpeg\",\".png\")) for f in os.listdir(test_img_dir)):\n",
    "        data_yaml[\"test\"] = test_img_dir\n",
    "    else:\n",
    "        if \"test\" in data_yaml:\n",
    "            del data_yaml[\"test\"]\n",
    "        print(\"‚ö†Ô∏è No se encontr√≥ carpeta test/ con im√°genes, se omitir√° del data.yaml\")\n",
    "    \n",
    "    with open(data_yaml_path, \"w\") as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "    \n",
    "    print(f\"‚úÖ data.yaml actualizado: {data_yaml_path}\")\n",
    "\n",
    "# Verificar estructura del dataset\n",
    "print(\"üìä Estructura del dataset:\")\n",
    "with open(data_yaml_path, \"r\") as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "    \n",
    "print(f\"  üìÅ Train: {len(os.listdir(data_yaml['train']))} im√°genes\")\n",
    "print(f\"  üìÅ Valid: {len(os.listdir(data_yaml['val']))} im√°genes\")\n",
    "if \"test\" in data_yaml:\n",
    "    print(f\"  üìÅ Test: {len(os.listdir(data_yaml['test']))} im√°genes\")\n",
    "print(f\"  üè∑Ô∏è Clases: {data_yaml['names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece35c4",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del Modelo YOLOv11 ü§ñüèãÔ∏è\n",
    "\n",
    "Entrenamos el modelo con nuestro dataset de nopales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44baf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo usando NopalPersonDetector o implementaci√≥n directa\n",
    "try:\n",
    "    from models.detector import NopalPersonDetector\n",
    "    print(\"‚úÖ NopalPersonDetector importado correctamente\")\n",
    "    \n",
    "    # Crear detector y entrenar\n",
    "    detector = NopalPersonDetector(config)\n",
    "    results = detector.train_nopal_model(data_yaml_path)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è No se pudo importar NopalPersonDetector, usando implementaci√≥n directa\")\n",
    "    \n",
    "    # Implementaci√≥n directa\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    print(\"ü§ñ Iniciando entrenamiento del modelo de nopales...\")\n",
    "    \n",
    "    # Cargar modelo base\n",
    "    model = YOLO(config['model']['base_model'])\n",
    "    \n",
    "    # Configuraci√≥n de entrenamiento\n",
    "    train_config = config['model']['training']\n",
    "    \n",
    "    # Entrenar\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=train_config['epochs'],\n",
    "        imgsz=train_config['image_size'],\n",
    "        batch=train_config['batch_size'],\n",
    "        patience=train_config['patience']\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Entrenamiento completado\")\n",
    "\n",
    "# Mostrar informaci√≥n del entrenamiento\n",
    "print(\"üìä Resumen del entrenamiento:\")\n",
    "print(f\"  ‚è±Ô∏è √âpocas completadas: {train_config['epochs']}\")\n",
    "print(f\"  üñºÔ∏è Tama√±o de imagen: {train_config['image_size']}px\")\n",
    "print(f\"  üì¶ Tama√±o de lote: {train_config['batch_size']}\")\n",
    "print(f\"  üéØ Paciencia: {train_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5c37b",
   "metadata": {},
   "source": [
    "## 6. Predicciones en Im√°genes de Test üñºÔ∏è (Nopales + Personas)\n",
    "\n",
    "Aplicamos el modelo entrenado para detectar nopales y el modelo preentrenado para detectar personas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelos y realizar predicciones en im√°genes\n",
    "if 'detector' in locals():\n",
    "    # Usar NopalPersonDetector\n",
    "    detector.load_models()\n",
    "    \n",
    "    # Verificar si hay im√°genes de test\n",
    "    with open(data_yaml_path, \"r\") as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    \n",
    "    if \"test\" in data_yaml:\n",
    "        test_img_dir = data_yaml[\"test\"]\n",
    "        if os.path.exists(test_img_dir) and os.listdir(test_img_dir):\n",
    "            predictions_dir = detector.predict_images(test_img_dir)\n",
    "            stats = detector.get_detection_stats(test_img_dir)\n",
    "            print(f\"üìä Estad√≠sticas: {stats}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No hay im√°genes de test disponibles\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dataset no incluye carpeta test\")\n",
    "        \n",
    "else:\n",
    "    # Implementaci√≥n directa\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Determinar rutas seg√∫n entorno\n",
    "    if 'google.colab' in sys.modules:\n",
    "        best_model_path = \"/content/runs/detect/train/weights/best.pt\"\n",
    "        predictions_dir = config['output']['predictions_dir']\n",
    "    else:\n",
    "        best_model_path = \"runs/detect/train/weights/best.pt\"\n",
    "        predictions_dir = config['output']['predictions_dir']\n",
    "    \n",
    "    os.makedirs(predictions_dir, exist_ok=True)\n",
    "    \n",
    "    # Cargar data.yaml\n",
    "    with open(data_yaml_path, \"r\") as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    \n",
    "    if \"test\" in data_yaml:\n",
    "        test_img_dir = data_yaml[\"test\"]\n",
    "        if os.path.exists(test_img_dir) and os.listdir(test_img_dir):\n",
    "            print(f\"üìÇ Im√°genes de test encontradas en: {test_img_dir}\")\n",
    "            \n",
    "            if os.path.exists(best_model_path):\n",
    "                nopal_model = YOLO(best_model_path)\n",
    "                person_model = YOLO(config['model']['person_model'])\n",
    "                \n",
    "                conf_thresh = config['model']['prediction']['confidence_threshold']\n",
    "                \n",
    "                res_nopal = nopal_model(test_img_dir, save=False, conf=conf_thresh)\n",
    "                res_person = person_model(test_img_dir, save=False, conf=conf_thresh)\n",
    "                \n",
    "                total_nopales = 0\n",
    "                total_persons = 0\n",
    "                \n",
    "                for idx, r_nopal in enumerate(res_nopal):\n",
    "                    img_path = r_nopal.path\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        continue\n",
    "                    \n",
    "                    annotated_img = img.copy()\n",
    "                    \n",
    "                    # Dibujar detecciones de nopales (verde)\n",
    "                    if r_nopal.boxes is not None:\n",
    "                        total_nopales += len(r_nopal.boxes)\n",
    "                        for box in r_nopal.boxes:\n",
    "                            x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0]]\n",
    "                            cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                            if box.conf is not None:\n",
    "                                label = f\"nopal: {box.conf.item():.2f}\"\n",
    "                                cv2.putText(annotated_img, label, (x1, y1 - 10), \n",
    "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Dibujar detecciones de personas (azul)\n",
    "                    if res_person[idx].boxes is not None:\n",
    "                        for box in res_person[idx].boxes:\n",
    "                            if int(box.cls) == 0:  # Solo personas (clase 0 en COCO)\n",
    "                                total_persons += 1\n",
    "                                x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0]]\n",
    "                                cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                                if box.conf is not None:\n",
    "                                    label = f\"person: {box.conf.item():.2f}\"\n",
    "                                    cv2.putText(annotated_img, label, (x1, y1 - 10), \n",
    "                                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    \n",
    "                    # Guardar imagen anotada\n",
    "                    out_path = os.path.join(predictions_dir, os.path.basename(img_path))\n",
    "                    cv2.imwrite(out_path, annotated_img)\n",
    "                \n",
    "                print(f\"üìå Guardadas {len(res_nopal)} im√°genes con detecciones\")\n",
    "                print(f\"üåµ Total nopales detectados: {total_nopales}\")\n",
    "                print(f\"üë• Total personas detectadas: {total_persons}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è No se encontr√≥ el modelo entrenado en: {best_model_path}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No hay im√°genes de test para evaluar\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è El dataset no incluye test/\")\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados en: {predictions_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b6520",
   "metadata": {},
   "source": [
    "## 7. Procesamiento de Video con Detecciones üé•\n",
    "\n",
    "Procesamos un video frame por frame aplicando detecci√≥n dual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de video\n",
    "if 'google.colab' in sys.modules:\n",
    "    video_filename = \"videoEjemplo.mp4\"\n",
    "    video_path = os.path.join(\"/content\", video_filename)\n",
    "    output_video_path = \"/content/output_video.mp4\"\n",
    "else:\n",
    "    # Para entorno local\n",
    "    video_filename = input(\"Ingrese el nombre del archivo de video (ej: video.mp4): \") or \"video.mp4\"\n",
    "    video_path = os.path.join(\"../data\", video_filename)\n",
    "    output_video_path = os.path.join(config['output']['videos_dir'], \"output_video.mp4\")\n",
    "    os.makedirs(config['output']['videos_dir'], exist_ok=True)\n",
    "\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"‚ö†Ô∏è No se encontr√≥ el archivo en {video_path}\")\n",
    "    if 'google.colab' in sys.modules:\n",
    "        print(\"üìÅ Por favor, sube tu video a Colab con el nombre 'videoEjemplo.mp4'\")\n",
    "    else:\n",
    "        print(f\"üìÅ Por favor, coloca tu video en la carpeta 'data/' con el nombre '{video_filename}'\")\n",
    "else:\n",
    "    if 'detector' in locals():\n",
    "        # Usar NopalPersonDetector\n",
    "        output_path = detector.process_video(video_path, \"output_video.mp4\")\n",
    "        print(f\"‚úÖ Video procesado guardado en: {output_path}\")\n",
    "    else:\n",
    "        # Implementaci√≥n directa\n",
    "        if 'google.colab' in sys.modules:\n",
    "            best_model_path = \"/content/runs/detect/train/weights/best.pt\"\n",
    "        else:\n",
    "            best_model_path = \"runs/detect/train/weights/best.pt\"\n",
    "            \n",
    "        if os.path.exists(best_model_path):\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            nopal_model = YOLO(best_model_path)\n",
    "            person_model = YOLO(config['model']['person_model'])\n",
    "            print(\"‚úÖ Modelos cargados (Nopal + Persona)\")\n",
    "            \n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "            \n",
    "            conf_thresh = config['model']['prediction']['confidence_threshold']\n",
    "            frame_count = 0\n",
    "            \n",
    "            print(\"üé¨ Procesando frames...\")\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                res_nopal = nopal_model(frame, conf=conf_thresh, verbose=False)\n",
    "                res_person = person_model(frame, conf=conf_thresh, verbose=False)\n",
    "                \n",
    "                annotated_frame = frame.copy()\n",
    "                \n",
    "                # Dibujar detecciones de nopales (verde)\n",
    "                if res_nopal[0].boxes is not None:\n",
    "                    for box in res_nopal[0].boxes:\n",
    "                        x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0]]\n",
    "                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        if box.conf is not None:\n",
    "                            label = f\"nopal: {box.conf.item():.2f}\"\n",
    "                            cv2.putText(annotated_frame, label, (x1, y1 - 10), \n",
    "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                # Dibujar detecciones de personas (azul)\n",
    "                if res_person[0].boxes is not None:\n",
    "                    for box in res_person[0].boxes:\n",
    "                        if int(box.cls) == 0:  # Solo personas\n",
    "                            x1, y1, x2, y2 = [int(coord) for coord in box.xyxy[0]]\n",
    "                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                            if box.conf is not None:\n",
    "                                label = f\"person: {box.conf.item():.2f}\"\n",
    "                                cv2.putText(annotated_frame, label, (x1, y1 - 10), \n",
    "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                \n",
    "                out.write(annotated_frame)\n",
    "                frame_count += 1\n",
    "                \n",
    "                # Mostrar progreso cada 100 frames\n",
    "                if frame_count % 100 == 0:\n",
    "                    print(f\"üìπ Procesados {frame_count} frames...\")\n",
    "                    \n",
    "                    # Mostrar preview en Colab\n",
    "                    if 'google.colab' in sys.modules:\n",
    "                        try:\n",
    "                            from google.colab.patches import cv2_imshow\n",
    "                            cv2_imshow(annotated_frame)\n",
    "                        except:\n",
    "                            pass\n",
    "            \n",
    "            cap.release()\n",
    "            out.release()\n",
    "            print(f\"‚úÖ Video procesado guardado en: {output_video_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No se encontraron pesos entrenados. No se proces√≥ el video.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d61197",
   "metadata": {},
   "source": [
    "## 8. Visualizaci√≥n de Resultados üìä\n",
    "\n",
    "Generamos gr√°ficos y visualizaciones de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70600acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de resultados usando ResultVisualizer\n",
    "try:\n",
    "    from utils.visualization import ResultVisualizer\n",
    "    print(\"‚úÖ ResultVisualizer importado correctamente\")\n",
    "    \n",
    "    # Crear visualizador\n",
    "    if 'google.colab' in sys.modules:\n",
    "        viz_dir = \"/content/visualizations\"\n",
    "    else:\n",
    "        viz_dir = \"../outputs/visualizations\"\n",
    "    \n",
    "    visualizer = ResultVisualizer(viz_dir)\n",
    "    \n",
    "    # Generar gr√°ficos de entrenamiento\n",
    "    if 'google.colab' in sys.modules:\n",
    "        training_plot = visualizer.plot_training_results(\"/content/runs/detect/train\")\n",
    "    else:\n",
    "        training_plot = visualizer.plot_training_results(\"runs/detect/train\")\n",
    "    \n",
    "    # Crear grilla de detecciones\n",
    "    if 'predictions_dir' in locals() and os.path.exists(predictions_dir):\n",
    "        grid_plot = visualizer.create_detection_grid(predictions_dir)\n",
    "        \n",
    "        # Estad√≠sticas de detecci√≥n\n",
    "        if 'stats' in locals():\n",
    "            stats_plot = visualizer.plot_detection_stats(stats)\n",
    "        elif 'total_nopales' in locals():\n",
    "            stats = {\n",
    "                'total_images': len(os.listdir(predictions_dir)),\n",
    "                'total_nopales': total_nopales,\n",
    "                'total_persons': total_persons\n",
    "            }\n",
    "            stats_plot = visualizer.plot_detection_stats(stats)\n",
    "    \n",
    "    print(\"‚úÖ Visualizaciones generadas correctamente\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è No se pudo importar ResultVisualizer, generando visualizaci√≥n b√°sica\")\n",
    "    \n",
    "    # Visualizaci√≥n b√°sica con matplotlib\n",
    "    if 'total_nopales' in locals():\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        categories = ['Nopales', 'Personas']\n",
    "        counts = [total_nopales, total_persons]\n",
    "        colors = ['green', 'blue']\n",
    "        \n",
    "        bars = ax.bar(categories, counts, color=colors, alpha=0.7)\n",
    "        ax.set_title('Detecciones Totales', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('N√∫mero de Detecciones')\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for bar, count in zip(bars, counts):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts) * 0.01, \n",
    "                   str(count), ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"üìä Estad√≠sticas finales:\")\n",
    "        print(f\"  üåµ Nopales detectados: {total_nopales}\")\n",
    "        print(f\"  üë• Personas detectadas: {total_persons}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No hay estad√≠sticas disponibles para visualizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90ca65",
   "metadata": {},
   "source": [
    "## 9. Descarga de Resultados üíæ\n",
    "\n",
    "Descargamos los archivos generados (espec√≠fico para Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de resultados (solo en Google Colab)\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import files\n",
    "    import zipfile\n",
    "    \n",
    "    print(\"üì¶ Preparando archivos para descarga...\")\n",
    "    \n",
    "    # Crear archivo ZIP con todos los resultados\n",
    "    zip_filename = \"/content/nopal_detector_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        # Agregar modelo entrenado si existe\n",
    "        if os.path.exists(\"/content/runs/detect/train/weights/best.pt\"):\n",
    "            zipf.write(\"/content/runs/detect/train/weights/best.pt\", \"models/best.pt\")\n",
    "            print(\"‚úÖ Modelo entrenado agregado al ZIP\")\n",
    "        \n",
    "        # Agregar predicciones si existen\n",
    "        if 'predictions_dir' in locals() and os.path.exists(predictions_dir):\n",
    "            for file in os.listdir(predictions_dir):\n",
    "                file_path = os.path.join(predictions_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    zipf.write(file_path, f\"predictions/{file}\")\n",
    "            print(\"‚úÖ Predicciones agregadas al ZIP\")\n",
    "        \n",
    "        # Agregar video procesado si existe\n",
    "        if os.path.exists(\"/content/output_video.mp4\"):\n",
    "            zipf.write(\"/content/output_video.mp4\", \"videos/output_video.mp4\")\n",
    "            print(\"‚úÖ Video procesado agregado al ZIP\")\n",
    "        \n",
    "        # Agregar visualizaciones si existen\n",
    "        if os.path.exists(\"/content/visualizations\"):\n",
    "            for file in os.listdir(\"/content/visualizations\"):\n",
    "                file_path = os.path.join(\"/content/visualizations\", file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    zipf.write(file_path, f\"visualizations/{file}\")\n",
    "            print(\"‚úÖ Visualizaciones agregadas al ZIP\")\n",
    "    \n",
    "    print(f\"üìÅ Archivo ZIP creado: {zip_filename}\")\n",
    "    \n",
    "    # Descargar archivos individuales\n",
    "    print(\"\\nüîΩ Iniciando descargas...\")\n",
    "    \n",
    "    # Descargar video procesado\n",
    "    if os.path.exists(\"/content/output_video.mp4\"):\n",
    "        print(\"üìπ Descargando video procesado...\")\n",
    "        files.download(\"/content/output_video.mp4\")\n",
    "    \n",
    "    # Descargar archivo ZIP completo\n",
    "    print(\"üì¶ Descargando archivo ZIP con todos los resultados...\")\n",
    "    files.download(zip_filename)\n",
    "    \n",
    "    print(\"‚úÖ ¬°Descargas completadas!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üìÅ Los resultados est√°n guardados en las siguientes ubicaciones:\")\n",
    "    print(f\"  ü§ñ Modelo entrenado: runs/detect/train/weights/best.pt\")\n",
    "    if 'predictions_dir' in locals():\n",
    "        print(f\"  üñºÔ∏è Predicciones: {predictions_dir}\")\n",
    "    if 'output_video_path' in locals():\n",
    "        print(f\"  üé• Video procesado: {output_video_path}\")\n",
    "    if 'viz_dir' in locals():\n",
    "        print(f\"  üìä Visualizaciones: {viz_dir}\")\n",
    "    \n",
    "    print(\"\\nüéØ Para usar el modelo entrenado en el futuro:\")\n",
    "    print(\"   from ultralytics import YOLO\")\n",
    "    print(\"   model = YOLO('runs/detect/train/weights/best.pt')\")\n",
    "    print(\"   results = model('imagen.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5e692",
   "metadata": {},
   "source": [
    "## üéâ Resumen del Proyecto\n",
    "\n",
    "### ‚úÖ Tareas Completadas:\n",
    "1. **Instalaci√≥n** de todas las librer√≠as necesarias\n",
    "2. **Descarga** del dataset desde Roboflow \n",
    "3. **Preparaci√≥n** autom√°tica del dataset con validaci√≥n\n",
    "4. **Entrenamiento** del modelo YOLOv11 para detecci√≥n de nopales\n",
    "5. **Predicciones** duales en im√°genes (nopales + personas)\n",
    "6. **Procesamiento** de video con detecciones en tiempo real\n",
    "7. **Visualizaci√≥n** de resultados y estad√≠sticas\n",
    "8. **Descarga** de todos los archivos generados\n",
    "\n",
    "### üèóÔ∏è Arquitectura del Proyecto:\n",
    "- **Modular**: Clases especializadas para cada funcionalidad\n",
    "- **Escalable**: F√°cil de extender con nuevas caracter√≠sticas\n",
    "- **Portable**: Funciona tanto en local como en Google Colab\n",
    "- **Configurable**: Par√°metros centralizados en archivos YAML\n",
    "\n",
    "### üìà Pr√≥ximos Pasos:\n",
    "- Ajustar hiperpar√°metros para mejor rendimiento\n",
    "- Agregar m√°s clases de detecci√≥n\n",
    "- Implementar seguimiento de objetos en video\n",
    "- Crear una interfaz web para el modelo\n",
    "\n",
    "### üöÄ ¬°Tu Detector de Nopales est√° listo para usar!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
