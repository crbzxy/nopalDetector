# Nopal Detector con YOLOv11 ğŸŒµ

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![YOLOv11](https://img.shields.io/badge/YOLOv11-Ultralytics-orange)](https://ultralytics.com)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

Proyecto de detecciÃ³n de nopales y personas usando YOLOv11, optimizado para entrenamiento local y en Google Colab.

## ğŸš€ CaracterÃ­sticas

- âœ… **DetecciÃ³n Dual:** Nopales + Personas en tiempo real
- âœ… **YOLOv11:** Ãšltima versiÃ³n de YOLO optimizada
- âœ… **Dataset AutomÃ¡tico:** IntegraciÃ³n con Roboflow
- âœ… **Arquitectura Modular:** CÃ³digo organizado y extensible
- âœ… **Multi-Entorno:** Compatible con local y Google Colab
- âœ… **Visualizaciones:** GrÃ¡ficos automÃ¡ticos de resultados
- âœ… **Seguridad:** Variables de entorno para API keys

## ğŸ› ï¸ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)
```bash
git clone tu-repositorio
cd nopalDetector
./setup.sh
```

### OpciÃ³n 2: Manual
```bash
# 1. Clonar repositorio
git clone tu-repositorio
cd nopalDetector

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con tu API key
```

## ğŸ“‹ Requisitos

- **Python:** 3.8 o superior
- **RAM:** 8GB mÃ­nimo (16GB recomendado)
- **GPU:** Opcional pero recomendada para entrenamiento
- **Espacio:** 5GB libres

### Dependencias Principales
```bash
ultralytics>=8.0.0     # YOLOv11
roboflow>=1.1.0        # Dataset management
opencv-python>=4.8.0   # Computer vision
python-dotenv>=1.0.0   # Environment variables
```

## âš™ï¸ ConfiguraciÃ³n

### 1. Variables de Entorno
```bash
# Copia la plantilla
cp .env.example .env

# Edita el archivo .env
nano .env
```

### 2. Obtener API Key de Roboflow
1. Ve a [Roboflow.com](https://roboflow.com/)
2. Crea una cuenta o inicia sesiÃ³n
3. Ve a **Settings â†’ API Keys**
4. Copia tu API key
5. PÃ©gala en el archivo `.env`:
   ```bash
   ROBOFLOW_API_KEY=tu_api_key_aqui
   ```

### 3. ConfiguraciÃ³n Opcional
```bash
# Ajustar parÃ¡metros del modelo (opcional)
MODEL_CONFIDENCE_THRESHOLD=0.3
MODEL_IOU_THRESHOLD=0.5
```

## ğŸ—‚ï¸ Estructura del Proyecto

```
nopalDetector/
â”œâ”€â”€ ğŸ“‹ README.md                      # DocumentaciÃ³n
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Dependencias Python
â”œâ”€â”€ ğŸš€ main.py                        # Script principal CLI
â”œâ”€â”€ âš™ï¸ setup.sh                       # ConfiguraciÃ³n automÃ¡tica
â”œâ”€â”€ ğŸ”’ .env.example                   # Plantilla de variables
â”œâ”€â”€ ğŸ”’ .gitignore                     # Archivos ignorados por Git
â”‚
â”œâ”€â”€ ğŸ“ config/                        # Configuraciones
â”‚   â”œâ”€â”€ model_config.yaml            # Config principal
â”‚   â””â”€â”€ training_config.yaml         # Config por entornos
â”‚
â”œâ”€â”€ ğŸ“ src/                           # CÃ³digo fuente
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset_manager.py       # GestiÃ³n de datasets
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ detector.py              # Detector YOLOv11
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                # Utilidades de configuraciÃ³n
â”‚       â”œâ”€â”€ visualization.py         # GrÃ¡ficos y visualizaciones
â”‚       â””â”€â”€ video_processor.py       # Procesamiento de video
â”‚
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â””â”€â”€ nopal_detector_training.ipynb # Notebook completo
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                         # Datos sin procesar
â”‚   â””â”€â”€ processed/                   # Datos procesados
â”‚
â”œâ”€â”€ ğŸ“ models/
â”‚   â””â”€â”€ weights/                     # Modelos entrenados
â”‚
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ predictions/                 # ImÃ¡genes con detecciones
â”‚   â”œâ”€â”€ videos/                      # Videos procesados
â”‚   â””â”€â”€ visualizations/              # GrÃ¡ficos y estadÃ­sticas
â”‚
â””â”€â”€ ğŸ“ logs/                         # Archivos de log
```

## ğŸ¯ Uso

### MÃ©todo 1: Notebook Interactivo (Recomendado)
```bash
# Activar entorno
source venv/bin/activate

# Abrir Jupyter Lab
jupyter lab notebooks/nopal_detector_training.ipynb
```

### MÃ©todo 2: LÃ­nea de Comandos
```bash
# Activar entorno
source venv/bin/activate

# Entrenar modelo
python main.py --mode train

# Predicciones en imÃ¡genes
python main.py --mode predict --input /ruta/a/imagenes/

# Procesar video
python main.py --mode video --input video.mp4 --output resultado.mp4
```

### MÃ©todo 3: Google Colab
1. Sube el notebook a Google Colab
2. Ejecuta las celdas en orden
3. Cuando se solicite, ingresa tu API key de Roboflow

## ğŸ“Š Configuraciones Predefinidas

El proyecto incluye 3 configuraciones optimizadas:

### ğŸ”§ Desarrollo (RÃ¡pido)
```yaml
# config/training_config.yaml -> development
epochs: 10
batch_size: 8
image_size: 416
model: yolo11s.pt
```

### ğŸ¯ ProducciÃ³n (Balanceado)
```yaml
# config/training_config.yaml -> production  
epochs: 100
batch_size: 16
image_size: 640
model: yolo11m.pt
```

### ğŸ§ª Experimento (MÃ¡xima PrecisiÃ³n)
```yaml
# config/training_config.yaml -> experiment
epochs: 200
batch_size: 8
image_size: 832
model: yolo11l.pt
```

## ğŸ“ˆ Flujo de Trabajo

1. **ğŸ“¥ InstalaciÃ³n:** Ejecutar `./setup.sh`
2. **ğŸ”‘ ConfiguraciÃ³n:** Editar `.env` con API key
3. **ğŸ“Š Entrenamiento:** Usar notebook o CLI
4. **ğŸ–¼ï¸ Predicciones:** Procesar imÃ¡genes de test
5. **ğŸ¥ Videos:** Procesar videos con detecciones
6. **ğŸ“ˆ AnÃ¡lisis:** Revisar visualizaciones automÃ¡ticas

## ğŸ”§ PersonalizaciÃ³n

### Cambiar Dataset
Edita en `config/model_config.yaml`:
```yaml
roboflow:
  workspace: "tu_workspace"
  project: "tu_project"
  version: 1
```

### Ajustar Modelo
```yaml
model:
  base_model: "yolo11n.pt"  # nano, s, m, l, x
  training:
    epochs: 50
    batch_size: 16
    image_size: 640
```

### Personalizar DetecciÃ³n
```yaml
prediction:
  confidence_threshold: 0.25  # MÃ¡s sensible
  iou_threshold: 0.45         # Menos superposiciÃ³n
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "ROBOFLOW_API_KEY not found"
```bash
# Verificar archivo .env
cat .env

# Debe contener:
ROBOFLOW_API_KEY=tu_api_key_real
```

### Error: "No module named 'ultralytics'"
```bash
# Activar entorno virtual
source venv/bin/activate

# Reinstalar dependencias
pip install -r requirements.txt
```

### Error de memoria durante entrenamiento
```yaml
# Reducir batch_size en config/model_config.yaml
training:
  batch_size: 4  # Reducir de 16 a 4
  image_size: 416  # Reducir de 640 a 416
```

### GPU no detectada
```bash
# Verificar CUDA
python -c "import torch; print(torch.cuda.is_available())"

# Instalar PyTorch con CUDA si es necesario
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“ Archivos Requeridos

### âœ… Lo que SÃ debes subir a Git:
- `README.md`, `requirements.txt`, `main.py`
- Todo el directorio `src/`
- Todo el directorio `config/`
- `notebooks/nopal_detector_training.ipynb`
- `.env.example` (plantilla sin API key real)
- `.gitignore`

### âŒ Lo que NO debes subir a Git:
- `.env` (contiene tu API key real)
- `venv/` (entorno virtual)
- `models/weights/*.pt` (modelos entrenados)
- `outputs/` (resultados generados)
- `data/raw/` (datasets descargados)
- `logs/` (archivos de log)

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- [Ultralytics](https://ultralytics.com/) por YOLOv11
- [Roboflow](https://roboflow.com/) por la gestiÃ³n de datasets
- Comunidad de Computer Vision por el soporte

---

**Â¿Problemas o preguntas?** Abre un [issue](../../issues) o contÃ¡ctanos.

## ğŸ¯ Uso RÃ¡pido

1. Abrir el notebook `notebooks/nopal_detector_training.ipynb`
2. Ejecutar las celdas en orden
3. Los resultados se guardarÃ¡n en `outputs/`

## ğŸ”§ ConfiguraciÃ³n

Editar los archivos en `config/` para personalizar:
- ParÃ¡metros del modelo
- ConfiguraciÃ³n de entrenamiento
- Rutas de datos

## ğŸ“Š Resultados

- ImÃ¡genes procesadas: `outputs/predictions/`
- Videos procesados: `outputs/videos/`
- Pesos del modelo: `models/weights/`